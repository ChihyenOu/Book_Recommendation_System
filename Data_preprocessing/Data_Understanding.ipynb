{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ls88BT0xNFfX"
   },
   "source": [
    "# Data Understanding on Original Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HP3YrC78NyVQ"
   },
   "source": [
    "## 1. Data Import (item.csv, transactions.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QKk1Ou_yTXP0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "transactions_dataset = pd.read_csv('../Original_dataset/transactions.csv',sep='|')\n",
    "items_dataset = pd.read_csv('../Original_dataset/items.csv',sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joRXH3j1fxXJ"
   },
   "source": [
    "## 2. Introduction to transaction dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "KmAlAGjzenSL",
    "outputId": "b0cb7f38-787c-4e72-f4ae-0e7b2c5733fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sessionID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>click</th>\n",
       "      <th>basket</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21310</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>73018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>40250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>46107</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sessionID  itemID  click  basket  order\n",
       "0          0   21310      1       0      0\n",
       "1          1   73018      1       0      0\n",
       "2          2   19194      1       0      0\n",
       "3          3   40250      1       0      0\n",
       "4          4   46107      1       0      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see the first 5 rows for transaction data\n",
    "transactions_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sRm3Wue7TArw",
    "outputId": "29f06ceb-faff-46cd-b3b9-0977d1e8258f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. total number of transactions is: 365143\n",
      "2. number of distinct sessions is: 271983\n",
      "3. number of rows with repeated session id is: 129501\n",
      "3. Repeated sessions include 36341 distinct session id\n",
      "4. maximum number of repetition for a session id is: 213\n",
      "5. number of distinct itemID that exists in transaction data is: 24909\n",
      "6. number of distinct items that we have information about them from more than one session id is:  14471\n"
     ]
    }
   ],
   "source": [
    "print('1. total number of transactions is:', transactions_dataset.sessionID.count())\n",
    "print ('2. number of distinct sessions is:',  len(pd.unique(transactions_dataset['sessionID'])))\n",
    "\n",
    "#we can label each instance by true whenever it is duplicated\n",
    "transactions_dataset['duplicated'] = transactions_dataset.duplicated(subset='sessionID', keep=False)\n",
    "duplicated_transactions = transactions_dataset[transactions_dataset['duplicated']!=False]\n",
    "print('3. number of rows with repeated session id is:',duplicated_transactions.sessionID.count())\n",
    "print ('3. Repeated sessions include',  len(pd.unique(duplicated_transactions['sessionID'])),'distinct session id')\n",
    "\n",
    "print('4. maximum number of repetition for a session id is:', duplicated_transactions['sessionID'].value_counts().max())\n",
    "print('5. number of distinct itemID that exists in transaction data is:', len(pd.unique(transactions_dataset['itemID'])))\n",
    "print('6. number of distinct items that we have information about them from more than one session id is: ', len(pd.unique(duplicated_transactions['itemID'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZUOXxVRgf5j"
   },
   "source": [
    "### **From the above result, we have the following data understanding:**\n",
    "1. we have 365,143 sessions in our transactions data set. Different session ids refer to different users. \n",
    "2. We have 271983 unique users. \n",
    "3. We have only one record from 65% (235,642) of users. In contrast from the other 35% (36,341) of users, we have 129,501 records. In average we have 3.6 records for each user.\n",
    "4. The maximum number of records for a user is 213. Anyway, the most important issue here, is that we can only rely on these 129,501 records to find associations.\n",
    "5. In next descriptions, we will see that all transactions history only covers 32% of books (24,909 books). This means that for the remaining 68% we do not have any information (even one click) in our transaction data set. \n",
    "6. Further, if for each book we want to explore transaction history from at least two users (i.e. searching for associations), these information is limited to 14,471 items (only 18.5% of books).\n",
    "\n",
    "**(Note that our recommender system cannot work in a way that is common for RS based on collaborative filtering! Simply because, when we want to recommend to most 5 similar items, we do not have access to user id! Put differently, we will recommend regardless of the identity of a user who searched our DB. Nevertheless, we still can rely on wisdom of crowd to some extent. Transaction dataset can be used to find out which items have been together (associations: click, basket, order). Further, transaction data set gives us the opportunity to distinguish between the head and the long tail.)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "sSKLB2Zkl9RI"
   },
   "outputs": [],
   "source": [
    "#delete the duplicated column\n",
    "del transactions_dataset['duplicated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data Distribution of Different Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "G83C2CC3hTjM",
    "outputId": "6c22f8f3-c233-4ee0-9fb0-221b26e1cfa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click</th>\n",
       "      <th>basket</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>365143.000000</td>\n",
       "      <td>365143.000000</td>\n",
       "      <td>365143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.233180</td>\n",
       "      <td>0.141202</td>\n",
       "      <td>0.048403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.069996</td>\n",
       "      <td>1.107574</td>\n",
       "      <td>0.268717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>118.000000</td>\n",
       "      <td>293.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               click         basket          order\n",
       "count  365143.000000  365143.000000  365143.000000\n",
       "mean        1.233180       0.141202       0.048403\n",
       "std         1.069996       1.107574       0.268717\n",
       "min         0.000000       0.000000       0.000000\n",
       "25%         1.000000       0.000000       0.000000\n",
       "50%         1.000000       0.000000       0.000000\n",
       "75%         1.000000       0.000000       0.000000\n",
       "max       118.000000     293.000000      28.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the data distribution of transaction dataset\n",
    "transactions_dataset[['click', 'basket','order']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CP7CjwMHiIDb"
   },
   "source": [
    "By looking at 75%, we find only one click and zero basket and order. This means that for a huge proportion of transactions, recorded information is just limited to a click! Looking at mean gives us more information about customer journey possibility of conversion from click to basket and then order. Finally, transaction data set can give us information about bestsellers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-w4BNVfSaoJv",
    "outputId": "401bade8-a131-481c-cf86-b77079ce28ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of distinct items with at least one click in our transaction history:  24620\n",
      "number of distinct items with at least one basket in our transaction history:  8746\n",
      "number of distinct items with at least one order in our transaction history:  5298\n"
     ]
    }
   ],
   "source": [
    "with_click_transactions = transactions_dataset [transactions_dataset['click'] > 0]\n",
    "with_basket_transactions = transactions_dataset [transactions_dataset['basket'] > 0]\n",
    "with_order_transactions = transactions_dataset [transactions_dataset['order'] > 0]\n",
    "print('number of distinct items with at least one click in our transaction history: ', len(pd.unique(with_click_transactions['itemID'])))\n",
    "print('number of distinct items with at least one basket in our transaction history: ', len(pd.unique(with_basket_transactions['itemID'])))\n",
    "print('number of distinct items with at least one order in our transaction history: ', len(pd.unique(with_order_transactions['itemID'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKMFpASsj3qm"
   },
   "source": [
    "In our transaction data set we have only 5,298 distinct items (6.8% of all books) that have been ordered. Only 11.2% of all books have ever been in the basket. Finally, 31.6% of all books have ever been clicked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Information about Transactional Association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mk72ubzPlC64",
    "outputId": "de0a0a6c-4cbf-444c-ff11-358590e818c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of distinct books that have been clicked by more than one session id: 14076\n",
      "number of distinct books that have been put in the basket by more than one session id:  7149\n",
      "number of distinct books that have been ordered by more than one session id:  3115\n"
     ]
    }
   ],
   "source": [
    "# now we focus on items that can give us information about associations.\n",
    "dup_click_trans = duplicated_transactions [duplicated_transactions['click'] > 0]\n",
    "dup_basket_trans = duplicated_transactions [duplicated_transactions['basket'] > 0]\n",
    "dup_order_trans = duplicated_transactions [duplicated_transactions['order'] > 0]\n",
    "print('number of distinct books that have been clicked by more than one session id:', len(pd.unique(dup_click_trans['itemID'])))\n",
    "print('number of distinct books that have been put in the basket by more than one session id: ', len(pd.unique(dup_basket_trans['itemID'])))\n",
    "print('number of distinct books that have been ordered by more than one session id: ', len(pd.unique(dup_order_trans['itemID'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bX2FFe3nOoy"
   },
   "source": [
    "Only 3,115 books (4% of all books) have been ordered by more than one session id, and only 18% of all books have been clicked by more than one session id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Introduction to Item Dataset\n",
    "### 3.1 Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "5t0-gPnufcVr",
    "outputId": "3cf8dfb7-6b55-4d1c-8289-ae3837f6e779"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>publisher</th>\n",
       "      <th>main topic</th>\n",
       "      <th>subtopics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21310</td>\n",
       "      <td>Princess Poppy: The Big Mix Up</td>\n",
       "      <td>Janey Louise Jones</td>\n",
       "      <td>Penguin Random House Children's UK</td>\n",
       "      <td>YFB</td>\n",
       "      <td>[5AH]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73018</td>\n",
       "      <td>Einfach zeichnen! Step by Step</td>\n",
       "      <td>Wiebke Krabbe</td>\n",
       "      <td>Schwager und Steinlein</td>\n",
       "      <td>AGZ</td>\n",
       "      <td>[5AJ,AGZ,WFA,YBG,YBL,YNA,YPA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19194</td>\n",
       "      <td>Red Queen 1</td>\n",
       "      <td>Victoria Aveyard</td>\n",
       "      <td>Orion Publishing Group</td>\n",
       "      <td>YFH</td>\n",
       "      <td>[5AP,FBA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40250</td>\n",
       "      <td>Meine Kindergarten-Freunde (Pirat)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ars Edition GmbH</td>\n",
       "      <td>YB</td>\n",
       "      <td>[5AC,5AD,YBG,YBL,YF]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46107</td>\n",
       "      <td>Mein großes Schablonen-Buch - Wilde Tiere</td>\n",
       "      <td>Elizabeth Golding</td>\n",
       "      <td>Edition Michael Fischer</td>\n",
       "      <td>WFTM</td>\n",
       "      <td>[WD,WFTM,YBG,YBL,YBLD,YBLN1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemID                                      title              author  \\\n",
       "0   21310             Princess Poppy: The Big Mix Up  Janey Louise Jones   \n",
       "1   73018             Einfach zeichnen! Step by Step       Wiebke Krabbe   \n",
       "2   19194                                Red Queen 1    Victoria Aveyard   \n",
       "3   40250         Meine Kindergarten-Freunde (Pirat)                 NaN   \n",
       "4   46107  Mein großes Schablonen-Buch - Wilde Tiere   Elizabeth Golding   \n",
       "\n",
       "                            publisher main topic  \\\n",
       "0  Penguin Random House Children's UK        YFB   \n",
       "1              Schwager und Steinlein        AGZ   \n",
       "2              Orion Publishing Group        YFH   \n",
       "3                    Ars Edition GmbH         YB   \n",
       "4             Edition Michael Fischer       WFTM   \n",
       "\n",
       "                       subtopics  \n",
       "0                          [5AH]  \n",
       "1  [5AJ,AGZ,WFA,YBG,YBL,YNA,YPA]  \n",
       "2                      [5AP,FBA]  \n",
       "3           [5AC,5AD,YBG,YBL,YF]  \n",
       "4   [WD,WFTM,YBG,YBL,YBLD,YBLN1]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7PlpnbFTf_Zb",
    "outputId": "f18e8f69-5790-428e-b1ab-99d5b6c8d9c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of items is 78030\n",
      "there are  72128 distinct titles\n",
      "there are  35970 distinct authors\n",
      "there are  7073 distinct publisher\n"
     ]
    }
   ],
   "source": [
    "print('total number of items is', items_dataset.itemID.count())\n",
    "print('there are ', len(pd.unique(items_dataset['title'])),'distinct titles')\n",
    "print('there are ', len(pd.unique(items_dataset['author'])),'distinct authors')\n",
    "print('there are ', len(pd.unique(items_dataset['publisher'])),'distinct publisher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5ToFFD0AV0B",
    "outputId": "d39c4ac5-5cde-42ee-c23c-c2b30ddeaea9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. there are 10095 books with same title, but different ids\n",
      "2. there are 7411 books with same title & author, but different ids among them, \n",
      "   there are 3182 distinct titles\n",
      "3. there are 4496 books that are duplicated at least one time. i.e. with same title, \n",
      "   author & publisher, but different ids among them, there are 1999 distinct titles\n",
      "4. there are 3830 books that are duplicated at least one time. i.e. with same title, \n",
      "   author, publisher & topic, but different ids among them, there are 1725 distinct title\n",
      "5. there are 3390 books that are duplicated at least one time. i.e. with same title, \n",
      "   author, publisher, topic & sub-topic, but different ids among them, \n",
      "   there are 1527 distinct title\n"
     ]
    }
   ],
   "source": [
    "items_dataset['dup-title'] = items_dataset.duplicated(subset=['title'], keep=False)\n",
    "items_dataset['dup-title-author'] = items_dataset.duplicated(subset=['title','author'], keep=False)\n",
    "items_dataset['dup-title-author-pub'] = items_dataset.duplicated(subset=['title','author','publisher'], keep=False)\n",
    "items_dataset['dup-title-author-pub-top'] = items_dataset.duplicated(subset=['title','author','publisher','main topic'], keep=False)\n",
    "items_dataset['dup-title-author-pub-top-sub'] = items_dataset.duplicated(subset=['title','author','publisher','main topic','subtopics'], keep=False)\n",
    "duplicated_itmes1 = items_dataset[items_dataset['dup-title']!=False]\n",
    "duplicated_itmes2 = items_dataset[items_dataset['dup-title-author']!=False]\n",
    "duplicated_itmes3 = items_dataset[items_dataset['dup-title-author-pub']!=False]\n",
    "duplicated_itmes4 = items_dataset[items_dataset['dup-title-author-pub-top']!=False]\n",
    "duplicated_itmes5 = items_dataset[items_dataset['dup-title-author-pub-top-sub']!=False]\n",
    "print('1. there are {} books with same title, but different ids'.format(duplicated_itmes1.itemID.count()))\n",
    "print('2. there are {} books with same title & author, but different ids among them, \\n   there are {} distinct titles'.format(duplicated_itmes2.itemID.count(), len(pd.unique(duplicated_itmes2['title']))))\n",
    "print('3. there are {} books that are duplicated at least one time. i.e. with same title, \\n   author & publisher, but different ids among them, there are {} distinct titles'.format(duplicated_itmes3.itemID.count(), len(pd.unique(duplicated_itmes3['title']))))\n",
    "print('4. there are {} books that are duplicated at least one time. i.e. with same title, \\n   author, publisher & topic, but different ids among them, there are {} distinct title'.format(duplicated_itmes4.itemID.count(), len(pd.unique(duplicated_itmes4['title']))))\n",
    "print('5. there are {} books that are duplicated at least one time. i.e. with same title, \\n   author, publisher, topic & sub-topic, but different ids among them, \\n   there are {} distinct title'.format(duplicated_itmes5.itemID.count(), len(pd.unique(duplicated_itmes5['title']))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dS5VTt2F_XoY"
   },
   "source": [
    "Basically, we should find a way to deal with repeted books in our dataset:\n",
    "1. 4496 records (5.8% of all records) can be considered duplicated. There is at least one other record with exactly same title, author, and publisher, but different id. (**The only possibility is having more than one edition from a book in our dataset. Since we don't have information about editions, we should decide how we want to deal with these records.**) Note that among these 4496 records, we have 3390 records that are completely duplicated. (There are at least one other records with exactly same title, author, publisher, topic, and sub-topic, but different ids). There are 440 (=3830-3390) records that are duplicated with regards to all features except sub-topic. It has no meaning that we have same books with same topics but different sub-topics. One simple remedy is to subsitute the sub-topic field of each repeated record by the union of sub-topics of all its twins. There are also 666 (=4496-3830) records among these duplicated items that are duplicated with regards to title, author and publisher but they have different topics and sub-topics. This situation is not possible in the real world. So, we can use the same remedy for both topic and sub-topic attributes.\n",
    "2. There are also 2,915 (=7411-4496) records (3.7% of all records) that are (**duplicated with regards to title and author, but published by different publishers.**)  It is very likely that our model, recommend these books when their similar items are search. \n",
    "3. Finally, there are 2,614 (=10095-7411) records (3.4%) of records with duplicated title, but are written by different authors. In the real world this could happen. But, we should consider one possibility: (**There may be error in author attribute data entry, or even it is possible that one entry only consists of subset of authors.**)  So, We should consider it in our data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "0AzIh_Vgm8M-"
   },
   "outputs": [],
   "source": [
    "items_dataset.drop(['dup-title-author','dup-title-author-pub','dup-title-author-pub-top','dup-title-author-pub-top-sub'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tB5G9EYEdmzi"
   },
   "source": [
    "One solid idea is to annotate the item dataset with language of each item based on the title. This idea simply rely on the assumption that a readers are interested in books that are written in only one specific language, or at least we can say that if a reader is interested in a book that is written in a specific language, (s)he will probably is interested in other books written in that language. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Understand the Main Topic Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jk6Ivg7wW-tG",
    "outputId": "17a67418-c3f6-478a-cbab-14265ff137fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of distinct main topics is: 700\n",
      "total number of books with something as main topic is: 77772\n"
     ]
    }
   ],
   "source": [
    "print ('number of distinct main topics is:',  len(pd.unique(items_dataset['main topic'])))\n",
    "items_filtered = items_dataset.dropna(subset=['main topic'])\n",
    "print('total number of books with something as main topic is:', items_filtered.itemID.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AoRcoGn_BDY"
   },
   "source": [
    "We have 700 distinct main topic in items dataset.  But, note that we have 258 item ids without any main topic (i.e. substraction of 77,772 from 78,030). So, we should solve the problem of missing values for these enteries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mKuZ-IXD-ZIZ",
    "outputId": "77b5a803-1cdd-41cc-8e7b-9538241b5618"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum length of main topic is: 10\n",
      "The minimum length of main topic is: 1\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "max_length_maintopic = 0\n",
    "for index, row in items_filtered.iterrows():\n",
    "    max_length_maintopic = max(max_length_maintopic,len(row['main topic']))\n",
    "    if (len(row['main topic']) <= 1): j = 1\n",
    "print ('The maximum length of main topic is:', max_length_maintopic)\n",
    "print ('The minimum length of main topic is:', j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZGhMbgdy5vw5",
    "outputId": "fe471563-6e23-46e3-b331-ab12751a4890"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution of main topic length is {min to max}: 291 17689 44551 13395 1105 740 0 0 0 1\n"
     ]
    }
   ],
   "source": [
    "j1 = 0\n",
    "j2 = 0\n",
    "j3 = 0\n",
    "j4 = 0\n",
    "j5 = 0\n",
    "j6 = 0\n",
    "j7 = 0\n",
    "j8 = 0\n",
    "j9 = 0\n",
    "j10 = 0\n",
    "for index, row in items_filtered.iterrows():\n",
    "    if (len(row['main topic']) == 1): j1 = j1 + 1\n",
    "    elif (len(row['main topic']) == 2): j2 = j2 + 1\n",
    "    elif (len(row['main topic']) == 3): j3 = j3 + 1\n",
    "    elif (len(row['main topic']) == 4): j4 = j4 + 1\n",
    "    elif (len(row['main topic']) == 5): j5 = j5 + 1\n",
    "    elif (len(row['main topic']) == 6): j6 = j6 + 1\n",
    "    elif (len(row['main topic']) == 7): j7 = j7 + 1\n",
    "    elif (len(row['main topic']) == 8): j8 = j8 + 1\n",
    "    elif (len(row['main topic']) == 9): j9 = j9 + 1\n",
    "    else: j10 = j10 + 1\n",
    "print ('distribution of main topic length is {min to max}:',j1,j2,j3,j4,j5,j6,j7,j8,j9,j10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDddYjbgFAIS"
   },
   "source": [
    "Clearly, we can omit one data point with length of main topic as 10, then we will have lengths between 1 and 7. Furthermore, the most common lengths are 2,3,4 which include 97% of all books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "394lVji22FsU",
    "outputId": "62670fcc-4de1-49ce-ae75-d4397b6d54e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of main topic with 5A (Interest Age) category: 0\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "topicage = '5A'\n",
    "for i in range (len(items_dataset)):\n",
    "    main_topic = str(items_dataset.at[i,'main topic'])\n",
    "    if (topicage in main_topic): j = j + 1\n",
    "print ('number of main topic with 5A (Interest Age) category:', j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Understand Suptopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWnUULtcEV_L",
    "outputId": "2c6dc67d-5831-4f5a-fff0-bc7a281eb593"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of subtopic with 5A (Interest Age) category: 12548\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "sub = '5A'\n",
    "for i in range (len(items_dataset)):\n",
    "    sub_topic = str(items_dataset.subtopics.loc[i])\n",
    "    if (sub in sub_topic): j = j + 1\n",
    "print ('number of subtopic with 5A (Interest Age) category:', j)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DMC2021-playground.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
